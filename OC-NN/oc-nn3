import tensorflow as tf
from tensorflow.keras import layers, regularizers
import numpy as np
import matplotlib.pyplot as plt
import sys
import random

sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

# Cargar el conjunto de datos MNIST
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Normalización de las imágenes
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

# Seleccionar solo las imágenes de la clase normal (ejemplo: clase 0)
x_train_normal = x_train[y_train == 0]
x_test_normal = x_test[y_test == 0]
x_test_anomalous = x_test[y_test != 0]

# Remodelar para el modelo
x_train_normal = x_train_normal.reshape(-1, 28 * 28)
x_test_normal = x_test_normal.reshape(-1, 28 * 28)
x_test_anomalous = x_test_anomalous.reshape(-1, 28 * 28)

# Definir el autoencoder
input_dim = x_train_normal.shape[1]

# Construcción del autoencoder
encoder = tf.keras.Sequential([
    layers.Input(shape=(input_dim,)),
    layers.Dense(128, activation='relu'),
    layers.Dense(64, activation='relu')
])

decoder = tf.keras.Sequential([
    layers.Dense(64, activation='relu'),
    layers.Dense(input_dim, activation='sigmoid')
])

autoencoder = tf.keras.Sequential([encoder, decoder])
autoencoder.compile(optimizer='adam', loss='mse')

# Entrenar el autoencoder solo con datos normales
autoencoder.fit(x_train_normal, x_train_normal, epochs=50, batch_size=64, validation_split=0.2, verbose=0)

# Extraer las características del encoder
x_train_encoded = encoder.predict(x_train_normal)

# Construcción de la red OC-NN (feed-forward) con el encoder preentrenado
oc_nn = tf.keras.Sequential([
    encoder,
    layers.Dense(32, activation='linear', kernel_regularizer=regularizers.l2(0.001)),
    layers.Dense(1, activation='sigmoid')  # Para decidir si es normal (1) o anómalo (0)
])

# Compilar OC-NN
oc_nn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000001), loss='binary_crossentropy', metrics=['accuracy'])

# Crear etiquetas (1 para normal) para entrenar la OC-NN
y_train_ocnn = np.ones(len(x_train_normal))

# Entrenar OC-NN solo con datos normales
history = oc_nn.fit(x_train_normal, y_train_ocnn, epochs=100, batch_size=64, validation_split=0.1, verbose=0)

# Obtener los puntajes de decisión en el conjunto de prueba
decision_scores_normal = oc_nn.predict(x_test_normal)
decision_scores_anomalous = oc_nn.predict(x_test_anomalous)

# Definir un umbral para la detección de anomalías (puedes ajustarlo según la proporción de anomalías deseada)
#threshold = np.percentile(decision_scores_normal, 99)  # Umbral ajustado al percentil 95 de datos normales
threshold = 0.9926;
# Clasificación de normal y anómalo según el umbral
predictions_normal = (decision_scores_normal > threshold).astype(int)
predictions_anomalous = (decision_scores_anomalous <= threshold).astype(int)


# Función para mostrar muestras con etiquetas predichas
def show_samples(data, predictions, title, num_samples=10):
    plt.figure(figsize=(15, 3))
    indices = random.sample(range(len(data)), num_samples)
    for i, idx in enumerate(indices):
        ax = plt.subplot(1, num_samples, i + 1)
        plt.imshow(data[idx].reshape(28, 28), cmap="gray")
        plt.title("Normal" if predictions[idx] == 1 else "Anómalo")
        plt.axis("off")
    plt.suptitle(title)
    plt.show()

# Mostrar muestras de datos normales con predicciones
show_samples(x_test_normal, predictions_normal, "Predicciones en datos normales")

# Mostrar muestras de datos anómalos con predicciones
show_samples(x_test_anomalous, predictions_anomalous, "Predicciones en datos anómalos")

# Mostrar distribución de puntajes
plt.hist(decision_scores_normal, bins=50, alpha=0.5, label="Normales")
plt.hist(decision_scores_anomalous, bins=50, alpha=0.5, label="Anómalas")
plt.axvline(threshold, color='red', linestyle='--', label="Umbral")
plt.legend()
plt.title("Distribución de los puntajes de decisión")
plt.xlabel("Puntaje")
plt.ylabel("Frecuencia")
plt.show()

# Mostrar curva de pérdida y precisión de entrenamiento
plt.plot(history.history['loss'], label='Pérdida de entrenamiento')
plt.plot(history.history['val_loss'], label='Pérdida de validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='Precisión de entrenamiento')
plt.plot(history.history['val_accuracy'], label='Precisión de validación')
plt.xlabel('Épocas')
plt.ylabel('Precisión')
plt.legend()
plt.show()

# Evaluación de resultados
accuracy_normal = np.mean(predictions_normal)  # Porcentaje de normales correctamente clasificados
accuracy_anomalous = np.mean(predictions_anomalous)  # Porcentaje de anómalos correctamente clasificados

print(f"Tasa de detección de normales: {accuracy_normal:.2f}")
print(f"Tasa de detección de anómalos: {accuracy_anomalous:.2f}")
